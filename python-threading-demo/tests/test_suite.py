"""
Pythonå¤šçº¿ç¨‹æ¼”ç¤ºç³»ç»Ÿæµ‹è¯•å¥—ä»¶
"""

import unittest
import threading
import time
import queue
import sys
import os
from unittest.mock import patch, MagicMock
import tempfile
import shutil

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from src.basic_thread_demo import BasicThreadDemo
from src.thread_pool_demo import ThreadPoolDemo
from src.producer_consumer_demo import ProducerConsumerDemo, Task, TaskPriority
from src.thread_sync_demo import ThreadSyncDemo
from src.file_downloader import FileDownloader, DownloadTask
from src.data_processor import DataProcessor, DataGenerator, DataChunk


class TestBasicThreadDemo(unittest.TestCase):
    """åŸºç¡€çº¿ç¨‹æ¼”ç¤ºæµ‹è¯•ç±»"""
    
    def setUp(self):
        self.demo = BasicThreadDemo()
    
    def test_thread_with_params(self):
        """æµ‹è¯•å¸¦å‚æ•°çš„çº¿ç¨‹"""
        self.demo.thread_with_params()
        
        # éªŒè¯ç»“æœ
        self.assertGreater(len(self.demo.results), 0)
        
        # éªŒè¯æ¯ä¸ªç»“æœéƒ½æœ‰æ­£ç¡®çš„å­—æ®µ
        for result in self.demo.results:
            self.assertIn('thread_id', result)
            self.assertIn('range', result)
            self.assertIn('result', result)
            self.assertIn('timestamp', result)
    
    def test_thread_with_return(self):
        """æµ‹è¯•çº¿ç¨‹è¿”å›å€¼å¤„ç†"""
        results = self.demo.thread_with_return()
        
        # éªŒè¯è¿”å›ç»“æœ
        self.assertIsInstance(results, list)
        self.assertGreater(len(results), 0)
        
        # éªŒè¯ç»“æœç»“æ„
        for result in results:
            self.assertIn('url_id', result)
            self.assertIn('status', result)


class TestThreadPoolDemo(unittest.TestCase):
    """çº¿ç¨‹æ± æ¼”ç¤ºæµ‹è¯•ç±»"""
    
    def setUp(self):
        self.demo = ThreadPoolDemo()
    
    def test_result_collection(self):
        """æµ‹è¯•ç»“æœæ”¶é›†åŠŸèƒ½"""
        results = self.demo.result_collection()
        
        # éªŒè¯è¿”å›çš„æ˜¯åˆ—è¡¨
        self.assertIsInstance(results, list)
        
        # éªŒè¯ç»“æœä¸­åŒ…å«æˆåŠŸå’Œå¯èƒ½çš„å¤±è´¥é¡¹
        successful_results = [r for r in results if r.get('status') == 'success']
        self.assertGreater(len(successful_results), 0)


class TestProducerConsumerDemo(unittest.TestCase):
    """ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¼”ç¤ºæµ‹è¯•ç±»"""
    
    def setUp(self):
        self.demo = ProducerConsumerDemo()
    
    def test_task_creation(self):
        """æµ‹è¯•ä»»åŠ¡åˆ›å»º"""
        task = Task("test_task", {"data": "test"}, TaskPriority.HIGH)
        
        self.assertEqual(task.task_id, "test_task")
        self.assertEqual(task.data, {"data": "test"})
        self.assertEqual(task.priority, TaskPriority.HIGH)
        self.assertIsNotNone(task.created_at)
    
    def test_task_priority_comparison(self):
        """æµ‹è¯•ä»»åŠ¡ä¼˜å…ˆçº§æ¯”è¾ƒ"""
        urgent_task = Task("urgent", {}, TaskPriority.URGENT)
        normal_task = Task("normal", {}, TaskPriority.NORMAL)
        
        # ä¼˜å…ˆçº§é«˜çš„ä»»åŠ¡åº”è¯¥å°äºä¼˜å…ˆçº§ä½çš„ä»»åŠ¡ï¼ˆç”¨äºä¼˜å…ˆçº§é˜Ÿåˆ—ï¼‰
        self.assertTrue(urgent_task < normal_task)
    
    def test_task_to_dict(self):
        """æµ‹è¯•ä»»åŠ¡å­—å…¸è½¬æ¢"""
        task = Task("test", {"key": "value"}, TaskPriority.HIGH)
        task_dict = task.to_dict()
        
        self.assertIn('task_id', task_dict)
        self.assertIn('data', task_dict)
        self.assertIn('priority', task_dict)
        self.assertIn('created_at', task_dict)


class TestThreadSyncDemo(unittest.TestCase):
    """çº¿ç¨‹åŒæ­¥æ¼”ç¤ºæµ‹è¯•ç±»"""
    
    def setUp(self):
        self.demo = ThreadSyncDemo()
    
    def test_shared_data_structure(self):
        """æµ‹è¯•å…±äº«æ•°æ®ç»“æ„"""
        self.assertIn('counter', self.demo.shared_data)
        self.assertIn('items', self.demo.shared_data)
        self.assertEqual(self.demo.shared_data['counter'], 0)
        self.assertEqual(len(self.demo.shared_data['items']), 0)


class TestFileDownloader(unittest.TestCase):
    """æ–‡ä»¶ä¸‹è½½å™¨æµ‹è¯•ç±»"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.downloader = FileDownloader(download_dir=self.temp_dir, max_workers=2)
    
    def tearDown(self):
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_download_task_creation(self):
        """æµ‹è¯•ä¸‹è½½ä»»åŠ¡åˆ›å»º"""
        url = "https://httpbin.org/bytes/1024"
        task = self.downloader.add_download(url)
        
        self.assertEqual(task.url, url)
        self.assertEqual(task.status, "pending")
        self.assertEqual(task.downloaded_bytes, 0)
        self.assertEqual(task.total_bytes, 0)
    
    def test_download_task_properties(self):
        """æµ‹è¯•ä¸‹è½½ä»»åŠ¡å±æ€§"""
        task = DownloadTask("http://example.com/file.txt", "test.txt")
        
        self.assertEqual(task.progress, 0.0)
        self.assertEqual(task.duration, 0.0)
        
        # æ¨¡æ‹Ÿä¸‹è½½è¿›åº¦
        task.total_bytes = 1000
        task.downloaded_bytes = 500
        self.assertEqual(task.progress, 50.0)
    
    @patch('requests.head')
    @patch('requests.get')
    def test_download_file(self, mock_get, mock_head):
        """æµ‹è¯•æ–‡ä»¶ä¸‹è½½åŠŸèƒ½"""
        # æ¨¡æ‹ŸHTTPå“åº”
        mock_head.return_value.headers = {'content-length': '1024'}
        mock_response = MagicMock()
        mock_response.headers = {'content-length': '1024'}
        mock_response.iter_content.return_value = [b'test_data']
        mock_get.return_value = mock_response
        
        task = DownloadTask("http://example.com/test.txt")
        result = self.downloader.download_file(task)
        
        self.assertEqual(result['status'], 'completed')
        self.assertIn('downloaded_bytes', result)


class TestDataProcessor(unittest.TestCase):
    """æ•°æ®å¤„ç†å™¨æµ‹è¯•ç±»"""
    
    def setUp(self):
        self.processor = DataProcessor(max_workers=2, chunk_size=100)
    
    def test_data_chunk_creation(self):
        """æµ‹è¯•æ•°æ®å—åˆ›å»º"""
        test_data = [{'id': i, 'value': i * 2} for i in range(50)]
        chunk = DataChunk("TEST_CHUNK", test_data, len(test_data))
        
        self.assertEqual(chunk.chunk_id, "TEST_CHUNK")
        self.assertEqual(len(chunk), 50)
        self.assertFalse(chunk.processed)
        self.assertIsNone(chunk.result)
    
    def test_data_splitting(self):
        """æµ‹è¯•æ•°æ®åˆ†å‰²åŠŸèƒ½"""
        test_data = [{'id': i} for i in range(250)]
        chunks = self.processor.split_data(test_data)
        
        # åº”è¯¥åˆ†å‰²ä¸º3ä¸ªå—ï¼ˆ100, 100, 50ï¼‰
        self.assertEqual(len(chunks), 3)
        self.assertEqual(len(chunks[0]), 100)
        self.assertEqual(len(chunks[1]), 100)
        self.assertEqual(len(chunks[2]), 50)
    
    def test_data_generator_sales_data(self):
        """æµ‹è¯•é”€å”®æ•°æ®ç”Ÿæˆå™¨"""
        sales_data = DataGenerator.generate_sales_data(100)
        
        self.assertEqual(len(sales_data), 100)
        
        # éªŒè¯æ•°æ®ç»“æ„
        for record in sales_data[:5]:  # æ£€æŸ¥å‰5æ¡
            self.assertIn('id', record)
            self.assertIn('product', record)
            self.assertIn('region', record)
            self.assertIn('quantity', record)
            self.assertIn('unit_price', record)
            self.assertIn('total_amount', record)
    
    def test_data_generator_log_data(self):
        """æµ‹è¯•æ—¥å¿—æ•°æ®ç”Ÿæˆå™¨"""
        log_data = DataGenerator.generate_log_data(100)
        
        self.assertEqual(len(log_data), 100)
        
        # éªŒè¯æ•°æ®ç»“æ„
        for record in log_data[:5]:  # æ£€æŸ¥å‰5æ¡
            self.assertIn('timestamp', record)
            self.assertIn('level', record)
            self.assertIn('service', record)
            self.assertIn('message', record)
            self.assertIn('response_time', record)


class TestThreadSafety(unittest.TestCase):
    """çº¿ç¨‹å®‰å…¨æµ‹è¯•ç±»"""
    
    def test_counter_thread_safety(self):
        """æµ‹è¯•è®¡æ•°å™¨çº¿ç¨‹å®‰å…¨"""
        counter = {'value': 0}
        lock = threading.Lock()
        
        def increment_with_lock():
            for _ in range(1000):
                with lock:
                    counter['value'] += 1
        
        threads = []
        for _ in range(5):
            thread = threading.Thread(target=increment_with_lock)
            threads.append(thread)
        
        for thread in threads:
            thread.start()
        
        for thread in threads:
            thread.join()
        
        # æœ‰é”çš„æƒ…å†µä¸‹åº”è¯¥å¾—åˆ°æ­£ç¡®ç»“æœ
        self.assertEqual(counter['value'], 5000)
    
    def test_queue_thread_safety(self):
        """æµ‹è¯•é˜Ÿåˆ—çº¿ç¨‹å®‰å…¨"""
        test_queue = queue.Queue()
        items_produced = 100
        items_consumed = []
        
        def producer():
            for i in range(items_produced):
                test_queue.put(f"item_{i}")
        
        def consumer():
            while len(items_consumed) < items_produced:
                try:
                    item = test_queue.get(timeout=1)
                    items_consumed.append(item)
                    test_queue.task_done()
                except queue.Empty:
                    break
        
        producer_thread = threading.Thread(target=producer)
        consumer_thread = threading.Thread(target=consumer)
        
        producer_thread.start()
        consumer_thread.start()
        
        producer_thread.join()
        consumer_thread.join()
        
        # éªŒè¯æ‰€æœ‰ç‰©å“éƒ½è¢«æ¶ˆè´¹
        self.assertEqual(len(items_consumed), items_produced)


class TestPerformance(unittest.TestCase):
    """æ€§èƒ½æµ‹è¯•ç±»"""
    
    def test_thread_pool_performance(self):
        """æµ‹è¯•çº¿ç¨‹æ± æ€§èƒ½"""
        import concurrent.futures
        
        def cpu_task(n):
            return sum(i * i for i in range(n))
        
        tasks = [1000] * 10
        
        # ä¸²è¡Œæ‰§è¡Œ
        start_time = time.time()
        serial_results = [cpu_task(n) for n in tasks]
        serial_time = time.time() - start_time
        
        # å¹¶è¡Œæ‰§è¡Œ
        start_time = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            parallel_results = list(executor.map(cpu_task, tasks))
        parallel_time = time.time() - start_time
        
        # éªŒè¯ç»“æœä¸€è‡´æ€§
        self.assertEqual(serial_results, parallel_results)
        
        # åœ¨CPUå¯†é›†å‹ä»»åŠ¡ä¸­ï¼Œç”±äºGILçš„å­˜åœ¨ï¼Œå¹¶è¡Œå¯èƒ½ä¸ä¼šæ˜¾è‘—æå‡æ€§èƒ½
        # ä½†æˆ‘ä»¬è‡³å°‘éªŒè¯å¹¶è¡Œç‰ˆæœ¬å¯ä»¥æ­£å¸¸å·¥ä½œ
        self.assertGreater(len(parallel_results), 0)
    
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        import psutil
        import gc
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss
        
        # åˆ›å»ºå¤§é‡æ•°æ®
        large_data = [{'id': i, 'data': 'x' * 100} for i in range(10000)]
        
        # å¤„ç†æ•°æ®
        processor = DataProcessor(max_workers=2, chunk_size=1000)
        chunks = processor.split_data(large_data)
        
        current_memory = process.memory_info().rss
        memory_increase = current_memory - initial_memory
        
        # æ¸…ç†
        del large_data
        del chunks
        gc.collect()
        
        # éªŒè¯å†…å­˜å¢é•¿åœ¨åˆç†èŒƒå›´å†…ï¼ˆå°äº100MBï¼‰
        self.assertLess(memory_increase, 100 * 1024 * 1024)


def run_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª è¿è¡ŒPythonå¤šçº¿ç¨‹æ¼”ç¤ºç³»ç»Ÿæµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestBasicThreadDemo,
        TestThreadPoolDemo,
        TestProducerConsumerDemo,
        TestThreadSyncDemo,
        TestFileDownloader,
        TestDataProcessor,
        TestThreadSafety,
        TestPerformance
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(
        verbosity=2,
        stream=sys.stdout,
        descriptions=True,
        failfast=False
    )
    
    result = runner.run(test_suite)
    
    # æ‰“å°æµ‹è¯•æ‘˜è¦
    print(f"\nğŸ“Š æµ‹è¯•æ‘˜è¦:")
    print(f"  è¿è¡Œæµ‹è¯•æ•°: {result.testsRun}")
    print(f"  æµ‹è¯•å¤±è´¥: {len(result.failures)}")
    print(f"  æµ‹è¯•é”™è¯¯: {len(result.errors)}")
    print(f"  è·³è¿‡æµ‹è¯•: {len(result.skipped)}")
    
    if result.failures:
        print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}")
    
    if result.errors:
        print(f"\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}")
    
    success_rate = ((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun) * 100
    print(f"\nğŸ¯ æµ‹è¯•æˆåŠŸç‡: {success_rate:.1f}%")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1)